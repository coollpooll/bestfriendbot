import os
import logging
from aiogram import Bot, Dispatcher, types, F
from aiogram.enums import ParseMode, DefaultBotProperties
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.filters import Command, CommandStart
from dotenv import load_dotenv
import asyncpg
from fastapi import FastAPI, Request
from openai import OpenAI
from pydub import AudioSegment

load_dotenv()
logging.basicConfig(level=logging.INFO)

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ASSISTANT_ID = os.getenv("ASSISTANT_ID")
DATABASE_URL = os.getenv("DATABASE_URL")
OWNER_CHAT_ID = int(os.getenv("OWNER_CHAT_ID", "520740282"))

bot = Bot(
    token=BOT_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.HTML)
)
dp = Dispatcher(storage=MemoryStorage())
app = FastAPI()
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# --- –ë–∞–∑–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è TTS (–æ–∑–≤—É—á–∫–∏)
tts_enabled = {}

# --- –ü—Ä–∏–º–µ—Ä Database –∫–ª–∞—Å—Å–∞ (–∑–∞–≥–ª—É—à–∫–∞)
class Database:
    def __init__(self, dsn):
        self.dsn = dsn
        self.pool = None

    async def connect(self):
        self.pool = await asyncpg.create_pool(self.dsn)

    async def disconnect(self):
        if self.pool:
            await self.pool.close()

    async def add_user(self, user_id):
        async with self.pool.acquire() as connection:
            await connection.execute(
                "INSERT INTO users (user_id, requests_today) VALUES ($1, $2) ON CONFLICT (user_id) DO NOTHING",
                user_id, 0
            )

db = Database(DATABASE_URL)

@dp.message(CommandStart())
async def cmd_start(message: types.Message):
    await db.add_user(message.from_user.id)
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π BEST FRIEND ü§ñ\n–ì–æ—Ç–æ–≤ –ø–æ–º–æ—á—å —Å –ª—é–±—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏!\n\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n/help ‚Äî –ø–æ–º–æ—â—å\n/status ‚Äî –ª–∏–º–∏—Ç—ã\n/tts_on ‚Äî –≤–∫–ª—é—á–∏—Ç—å –æ–∑–≤—É—á–∫—É (—Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω)\n/tts_off ‚Äî –≤—ã–∫–ª—é—á–∏—Ç—å –æ–∑–≤—É—á–∫—É (—Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω)")

@dp.message(Command("help"))
async def cmd_help(message: types.Message):
    await message.answer("–°–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥:\n/start ‚Äî –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫\n/status ‚Äî –ª–∏–º–∏—Ç—ã\n/tts_on ‚Äî –≤–∫–ª—é—á–∏—Ç—å –æ–∑–≤—É—á–∫—É (—Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω)\n/tts_off ‚Äî –≤—ã–∫–ª—é—á–∏—Ç—å –æ–∑–≤—É—á–∫—É (—Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω)")

@dp.message(Command("status"))
async def cmd_status(message: types.Message):
    await message.answer("–õ–∏–º–∏—Ç—ã: 3 –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å—É—Ç–∫–∏ (–µ—Å–ª–∏ –Ω–µ –∞–¥–º–∏–Ω).")

@dp.message(Command("tts_on"))
async def cmd_tts_on(message: types.Message):
    if message.from_user.id == OWNER_CHAT_ID:
        tts_enabled[OWNER_CHAT_ID] = True
        await message.answer("–û–∑–≤—É—á–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞.")
    else:
        await message.answer("–£ —Ç–µ–±—è –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥–µ.")

@dp.message(Command("tts_off"))
async def cmd_tts_off(message: types.Message):
    if message.from_user.id == OWNER_CHAT_ID:
        tts_enabled[OWNER_CHAT_ID] = False
        await message.answer("–û–∑–≤—É—á–∫–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞.")
    else:
        await message.answer("–£ —Ç–µ–±—è –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥–µ.")

@app.on_event("startup")
async def on_startup():
    await db.connect()
    logging.info("Database connected")

@app.on_event("shutdown")
async def on_shutdown():
    await db.disconnect()
    logging.info("Database disconnected")

@app.post("/webhook")
async def telegram_webhook(request: Request):
    body = await request.json()
    update = types.Update(**body)
    await dp.feed_update(bot, update)
    return {"ok": True}

# ------- –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è --------
@dp.message(F.text)
async def handle_text(message: types.Message):
    try:
        completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É."},
                {"role": "user", "content": message.text}
            ]
        )
        gpt_answer = completion.choices[0].message.content
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç GPT: {e}")
        await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ò–ò ü§ñ")
        return

    await message.answer(gpt_answer)

    # –û–∑–≤—É—á–∫–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –¥–ª—è –∞–¥–º–∏–Ω–∞)
    if tts_enabled.get(OWNER_CHAT_ID) and message.from_user.id == OWNER_CHAT_ID:
        await send_tts_voice(message, gpt_answer)

# ------- –ì–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ Whisper + pydub --------
@dp.message(F.voice)
async def handle_voice(message: types.Message):
    file_id = message.voice.file_id
    file = await bot.get_file(file_id)
    ogg_path = f"voice_{message.from_user.id}.ogg"
    wav_path = f"voice_{message.from_user.id}.wav"
    await bot.download_file(file.file_path, ogg_path)
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º ogg –≤ wav (—Ñ–æ—Ä–º–∞—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–Ω–∏–º–∞–µ—Ç OpenAI)
    try:
        audio = AudioSegment.from_file(ogg_path, format="ogg")
        audio.export(wav_path, format="wav")
    except Exception as e:
        await message.answer("–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ üò¢")
        return
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ OpenAI Whisper
    try:
        with open(wav_path, "rb") as audio_file:
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="text",
                language="ru"
            )
        prompt = transcript.text if hasattr(transcript, "text") else str(transcript)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ –≥–æ–ª–æ—Å–∞: {e}")
        await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ üòî")
        return
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        try:
            os.remove(ogg_path)
            os.remove(wav_path)
        except Exception:
            pass
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ GPT-4o
    try:
        completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É."},
                {"role": "user", "content": prompt}
            ]
        )
        gpt_answer = completion.choices[0].message.content
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç GPT: {e}")
        await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ò–ò ü§ñ")
        return

    await message.answer(gpt_answer)

    # –û–∑–≤—É—á–∫–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –¥–ª—è –∞–¥–º–∏–Ω–∞)
    if tts_enabled.get(OWNER_CHAT_ID) and message.from_user.id == OWNER_CHAT_ID:
        await send_tts_voice(message, gpt_answer)

# ---------- TTS (Text-to-Speech) ----------
async def send_tts_voice(message, text):
    try:
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã (OpenAI TTS max ~4096)
        text = text[:4096]
        speech_response = openai_client.audio.speech.create(
            model="tts-1",
            voice="alloy",
            input=text,
        )
        filename = f"tts_{message.from_user.id}.mp3"
        with open(filename, "wb") as f:
            f.write(speech_response.content)
        with open(filename, "rb") as f:
            await bot.send_voice(message.chat.id, f)
        os.remove(filename)
    except Exception as e:
        logging.error(f"TTS –æ—à–∏–±–∫–∞: {e}")
        await message.answer("–û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∫–∏ –æ—Ç–≤–µ—Ç–∞.")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=10000)













